# -*- coding: utf-8 -*-
"""BAIG Python Challenge 2023:  Team Bread 🍞

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PA8HVqx4_C_WSoPAWgM-ZFlONjhjBdQQ

# BAIG Python Challenge 2023:  **Team Bread 🍞**

## Download Essential Modules - Matplotlib, Pandas, Seaborn, Openpyxl
"""

# First time installation
!pip install matplotlib pandas seaborn openpyxl

"""## Import Modules and Link Dataset"""

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np

dfLink = 'https://github.com/aureliashabi/BAIGPythonChallenge2023/raw/main/Copy%20of%20Heng%20Ong%20Huat_data%20.xlsx'
df = pd.read_excel(dfLink, engine='openpyxl')

"""## Dataset Cleaning and Preparation
For the later part of the notebook, this portion of data cleaning will have to be re-ran on some visualisation as I'm not really familiar with the flow of ipynb as compared to VSC. I've included it before the visualisations so you do not need to re-scroll up. Apologies!
"""

dfLink = 'https://github.com/aureliashabi/BAIGPythonChallenge2023/raw/main/Copy%20of%20Heng%20Ong%20Huat_data%20.xlsx'
df = pd.read_excel(dfLink, engine='openpyxl')

# Defining the possible value based on the table
ruleYear = (df['Year_Birth'] >= 1893) & (df['Year_Birth'] <= 1996)
ruleGender = df['Gender'].isin(['M', 'F'])
ruleEducation = df['Education'].isin(['Degree', 'Master', 'JC', 'PhD', 'Poly'])
ruleMaritial = df['Marital_Status'].isin(['Married', 'Single', 'Together', 'Divorced'])

# Replace other values according to the rules
df['Race'] = df['Race'].replace('Arab', 'others')
df['Property Type'] = df['Property Type'].replace({'3RM': '3rm', '5RM': '5rm', 'FOUR': '4rm'})
df['Car'] = df['Car'].replace({'Yes': '1', 'No': '0'})

# Drop values that do not conform to the rules
df = df[ruleYear & ruleGender & ruleEducation & ruleMaritial]

# Address Null and Invalid values
nullValue = df.isnull().sum()
df = df[~df['Property Type'].isin([0, '.','#N/A', None])]
df = df.dropna(subset=['Income','Property Type'])

# Assuming that individual's income value correspond with their property type
# Automatically fill null income values based on mean of the respective property type
meanIncome = df.groupby('Property Type')['Income'].transform('mean').round(0)
df['Income'] = df['Income'].fillna(meanIncome)

# Addressing Income outliers (i.e 66666 value) via Inter Quartile Range
Q1 = df['Income'].quantile(0.25)
Q3 = df['Income'].quantile(0.75)
IQR = Q3 - Q1
incomeOutliers = (df['Income'] < Q1 - 1.5 * IQR) | (df['Income'] > Q3 + 1.5 * IQR)
df = df[~incomeOutliers]

# View Unique Values in each columns ; This is to ensure that values are as accordance to those specified in the possible values table.
for column in df.columns:
    unique_values = df[column].unique()
    #print(f"Unique values in column '{column}': {unique_values}")

# Defining the possible value based on the table
ruleYear = (df['Year_Birth'] >= 1893) & (df['Year_Birth'] <= 1996)
ruleGender = df['Gender'].isin(['M', 'F'])
ruleEducation = df['Education'].isin(['Degree', 'Master', 'JC', 'PhD', 'Poly'])
ruleMaritial = df['Marital_Status'].isin(['Married', 'Single', 'Together', 'Divorced'])

# Replace other values according to the rules
df['Race'] = df['Race'].replace('Arab', 'others')
df['Property Type'] = df['Property Type'].replace({'3RM': '3rm', '5RM': '5rm', 'FOUR': '4rm'})
df['Car'] = df['Car'].replace({'Yes': '1', 'No': '0'})

# Drop values that do not conform to the rules
df = df[ruleYear & ruleGender & ruleEducation & ruleMaritial]

# Address Null and Invalid values
nullValue = df.isnull().sum()
df = df[~df['Property Type'].isin([0, '.','#N/A', None])]
df = df.dropna(subset=['Income','Property Type'])

# Assuming that individual's income value correspond with their property type
# Automatically fill null income values based on mean of the respective property type
meanIncome = df.groupby('Property Type')['Income'].transform('mean').round(0)
df['Income'] = df['Income'].fillna(meanIncome)

# Addressing Income outliers (i.e 66666 value) via Inter Quartile Range
Q1 = df['Income'].quantile(0.25)
Q3 = df['Income'].quantile(0.75)
IQR = Q3 - Q1
incomeOutliers = (df['Income'] < Q1 - 1.5 * IQR) | (df['Income'] > Q3 + 1.5 * IQR)
df = df[~incomeOutliers]

"""## Drawing of Insights from Visualisation

### Graph 1: **Correlation between Education and Income**

The purpose of this graph is to draw a correlation between education and income level. It also seek to address the common assumption that higher education level has a direct correlation to higher income levels.

The boxplot shows the median, min/max values as well as the upper & lower percentile of income by education level.
The mean income amount of each education level has also been identified and marked with a white x.

1. Surprisingly, PhD holders do not have the highest range of earning.
2. Little correlation to higher education level = higher income level
3. JC have the highest range and high, whereas Degree have the lowest low
"""

# Creating an ordered list per education level
educationLvl = ['Poly', 'JC', 'Degree', 'Master', 'PhD']

meanVal = df.groupby('Education')['Income'].mean()
sns.set(style="whitegrid")
plt.figure(figsize=(8, 6))
ax = sns.boxplot(data=df, x="Education", y="Income", order=educationLvl, showmeans=True, meanprops={"marker":"x", "markeredgecolor":"white", "markersize":"4"})
plt.xlabel("Education")
plt.ylabel("Income")
for i, order in enumerate(educationLvl):
    mean = meanVal.loc[order]
    ax.text(i, mean, f'${mean:.0f}', ha='center', va='bottom', color='black', fontsize=10)
plt.show()

"""### Graph 2: **Correlation between Income Level and Spendings**
The purpose of this graph is to explore the spending on each category (Groceries, Utilities, Children Allowance etc) of each income level. This can also address the assumption that spendings for the higher income level is higher across __all__ categories as compared to lower income levels.

The barplot shows the average spending for each expense category (i.e Groceries, Utilities etc) by the different income level (Low, Medium, High).

1. The grocery, utilities and eating out spending is about the same across all income level at ~$685, ~$350 and ~$545 respectively.
2. The High Income group have extremely low children allowance, with many (93%) of them putting "0". Thereby, this may not be a good reflection of the entire high income populus as it might mean that they refuse to answer.
3. The High Income group spends more in the "Others" category as compared to the other groups. This may mean investments, leisure or luxury items.

By understanding the spending of the various income level, GST relief schemes can be tailored around these spendings to mitigate inflation.
"""

bins = pd.cut(df['Income'], bins=3, labels=['Low', 'Medium', 'High'])
binRange = [(round(interval.left, 0), round(interval.right, 0)) for interval in pd.cut(df['Income'], bins=3).cat.categories]
df['incomeBin'] = bins

dfMelt = pd.melt(df, id_vars=['incomeBin'], value_vars=['Groceries', 'Utilities (Water & Electricity', 'Eating out', 'Children Allowances', 'Public Transport / Gas', 'Others'])
palette = sns.color_palette("viridis", n_colors=len(df['incomeBin'].unique()))
plt.figure(figsize=(14, 8))
ax = sns.barplot(data=dfMelt, x='variable', y='value', hue='incomeBin', palette=palette, errorbar=None)
for p in ax.patches:
    ax.annotate(f'${p.get_height():.0f}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=8)

plt.xlabel("Expenses Category")
plt.ylabel("Amount ($)")
plt.title("Mean Expenses by Income Level")
plt.legend(title="Income Level", loc='upper right')

plt.tight_layout()
plt.show()

"""### Graph 3 : Proportion of income spent on Groceries Spending accross Age and Household Profile
This graph aims to provide an overview of the spending of groceries in proportion of their total income based on a household profile (residing with/without parents and/or children by room type). The rationale is that it allows to visualise and target the necessary households first that require assistance from said government campaign due to the inflationary environment.


"""

df['Groceries'] *= 12
df['Eating out'] *= 12
df['Utilities (Water & Electricity'] *= 12

avgGroc = (df['Groceries'] / df['Income']).mean() * 100
avgEatOut = (df['Eating out'] / df['Income']).mean() * 100
avgUtilities = (df['Utilities (Water & Electricity'] / df['Income']).mean() * 100

remain = 100 - avgGroc - avgEatOut - avgUtilities

pie = {'Category': ['Groceries', 'Eating Out', 'Utilities' , 'Rest of Income'],
                'Percentage': [avgGroc, avgEatOut, avgUtilities, remain]}
plotPie = pd.DataFrame(pie)

plt.figure(figsize=(6, 6))
plt.title('Average Distribution of Spending Categories')
plt.pie(plotPie['Percentage'], labels=plotPie['Category'], autopct='%1.1f%%', startangle=90)

plt.show()

# If a value error occur, run the above code block.

"""### Graph 4: Correlation between Income Level, Loans and Credit Card
The purpose of this graph is to figure out the percentage of people in each income level that have a credit card and/or loans. This will shed light on the impacts on the GST increase (1% increase on a 300k mortgage loan is a lot, or 1% increase in credit-card repayment).

It also serve to answer that if majority of the people have loans or credit cards, perhaps loan relief or credit card relief schemes can be created to help mitigate inflation.

https://www.dbs.com/gst-changes/default.page <br>
Credit cards – annual fees, chargeback fees are subjected to GST
"""

import pandas as pd
dfLink = 'https://github.com/aureliashabi/BAIGPythonChallenge2023/raw/main/Copy%20of%20Heng%20Ong%20Huat_data%20.xlsx'
df = pd.read_excel(dfLink, engine='openpyxl')

# Defining the possible value based on the table
ruleYear = (df['Year_Birth'] >= 1893) & (df['Year_Birth'] <= 1996)
ruleGender = df['Gender'].isin(['M', 'F'])
ruleEducation = df['Education'].isin(['Degree', 'Master', 'JC', 'PhD', 'Poly'])
ruleMaritial = df['Marital_Status'].isin(['Married', 'Single', 'Together', 'Divorced'])

# Replace other values according to the rules
df['Race'] = df['Race'].replace('Arab', 'others')
df['Property Type'] = df['Property Type'].replace({'3RM': '3rm', '5RM': '5rm', 'FOUR': '4rm'})
df['Car'] = df['Car'].replace({'Yes': '1', 'No': '0'})

# Drop values that do not conform to the rules
df = df[ruleYear & ruleGender & ruleEducation & ruleMaritial]

# Address Null and Invalid values
nullValue = df.isnull().sum()
df = df[~df['Property Type'].isin([0, '.','#N/A', None])]
df = df.dropna(subset=['Income','Property Type'])

# Assuming that individual's income value correspond with their property type
# Automatically fill null income values based on mean of the respective property type
meanIncome = df.groupby('Property Type')['Income'].transform('mean').round(0)
df['Income'] = df['Income'].fillna(meanIncome)

# Addressing Income outliers (i.e 66666 value) via Inter Quartile Range
Q1 = df['Income'].quantile(0.25)
Q3 = df['Income'].quantile(0.75)
IQR = Q3 - Q1
incomeOutliers = (df['Income'] < Q1 - 1.5 * IQR) | (df['Income'] > Q3 + 1.5 * IQR)
df = df[~incomeOutliers]

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import numpy as np
anyCreditCard = 'Credit Card'
anyLoan = 'Loan (Car/ Housing / Student)'
df[anyLoan] = df[anyLoan].map({'Yes': 1, 'No': 0})

bins = pd.cut(df['Income'], bins=3, labels=['Low', 'Medium', 'High'])
binRange = [(round(interval.left, 0), round(interval.right, 0)) for interval in pd.cut(df['Income'], bins=3).cat.categories]
df['incomeBin'] = bins

incomeLoansCardDF = df.groupby(['incomeBin'])[[anyCreditCard, anyLoan]].mean().reset_index()
melted_df = pd.melt(incomeLoansCardDF, id_vars=['incomeBin'], value_vars=[anyCreditCard, anyLoan], var_name='Category', value_name='Average Value')

plt.figure(figsize=(12, 8))
ax = sns.barplot(x='incomeBin', y='Average Value', hue='Category', data=melted_df, palette='pastel', errorbar=None)

plt.xlabel('Income Level')
plt.ylabel('Average Value')
plt.title('Average Credit Card and Loans by Income Level and Gender')

for p in ax.patches:
    if p.get_height() > 0.01:
        ax.annotate(f'{p.get_height() * 100:.0f}%', (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', xytext=(0, 10), textcoords='offset points')

plt.legend(loc='center left', bbox_to_anchor=(0.025, 0.5))
plt.show()